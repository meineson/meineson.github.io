<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="MEINESON,meineson@gmail.com"><title>FFMPEG代码（API）推流RTMP的音视频不同步问题分析 · MBSTUDIO</title><meta name="description" content="FFMPEG基于命令行方式进行RTMP或RTSP（以及最新的WHIP）推流使用很普遍，基本上在桌面或服务器环境（Linux、Windows）下，大家习惯于直接用命令行方式使用，方便移植和调整，包括许多NAS上的视频转码也大多这种方式。

问题：音视频不同步
命令行方式用的人多了，原始的C语言的API"><meta name="keywords" content="mbstudio,ICT,RCS,Deep Learning,Digital Twin,AIGC"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><meta name="generator" content="Hexo 7.3.0"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">MBSTUDIO</a></h3><div class="description"><p>魔瓶工作室 since 2001 /RCS OS IOT AI DT/</p></div></div></div><ul class="social-links"><li><a href="mailto:meineson@gmail.com"><i class="fa fa-envelope">         </i></a></li><li><a target="_blank" rel="noopener" href="https://weibo.com/meineson"><i class="fa fa-weibo"></i></a></li><li><a target="_blank" rel="noopener" href="http://github.com/meineson"><i class="fa fa-github"></i></a></li></ul><div class="footer"></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/about">关于</a></li><li><a href="/archives">归档</a></li><li><a href="/links">友链</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div><div class="avatar"><img src="/images/me.png"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>FFMPEG代码（API）推流RTMP的音视频不同步问题分析</a></h3></div><div class="post-content"><blockquote>
<p>FFMPEG基于命令行方式进行RTMP或RTSP（以及最新的WHIP）推流使用很普遍，基本上在桌面或服务器环境（Linux、Windows）下，大家习惯于直接用命令行方式使用，方便移植和调整，包括许多NAS上的视频转码也大多这种方式。</p>
</blockquote>
<p><strong>问题：音视频不同步</strong></p>
<p>命令行方式用的人多了，原始的C语言的API方式编码实现就变得稀罕了，基于你去市面上找不到一本正经讲这方面知识的教材或教程，网上的片段，由于FFMPEG最近版本变化非常快，很多都是过时或者“只输出代码不输出知识”——不讲原理，许多代码就这么稀里糊涂的带病上线，凑合用吧。所以许多多媒体、流媒体的应用或服务经常出现各自奇葩问题，大多是由于程序员一知半解搞出来的事。</p>
<p>这不最近有一个项目里，服务端是使用的ZLMmediakit，客户端是Android客户端调用FFMPEG 8.0 JNI方式，实现抓取摄像头、麦克风数据，使用h264mediacodec进行硬件编码，进行RTMP（H264+AAC）推流。</p>
<p>服务端声音和视频都收到了，但明显卡顿异常，用VLC直接播放，视频是实时的，但音频延时甚至达到10秒的问题，就这个问题，我们使用程序员的方式进行debug分析处理。</p>
<p><strong>问题分析</strong></p>
<ul>
<li>善用ffprobe分析</li>
</ul>
<p>ffprobe是最适合对ffmpeg产生的视频&#x2F;视频流进行分析的工具，它能准确打印ffmpeg产生的各类数据的细节，能方便对照源码。</p>
<p>先看下视频基本信息, 使用.&#x2F;ffprobe 视频url地址</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">./ffprobe   rtmp://172.21.132.230:1935/rtc/test            </span><br><span class="line">ffprobe version 8.0 Copyright (c) 2007-2025 the FFmpeg developers</span><br><span class="line">  built with Apple clang version 17.0.0 (clang-1700.0.13.5)</span><br><span class="line">  configuration: --enable-openssl --enable-muxer=whip --enable-static --enable-libopus --enable-libx264 --enable-libx265 --enable-nonfree --enable-gpl --disable-x86asm</span><br><span class="line">  libavutil      60.  8.100 / 60.  8.100</span><br><span class="line">  libavcodec     62. 11.100 / 62. 11.100</span><br><span class="line">  libavformat    62.  3.100 / 62.  3.100</span><br><span class="line">  libavdevice    62.  1.100 / 62.  1.100</span><br><span class="line">  libavfilter    11.  4.100 / 11.  4.100</span><br><span class="line">  libswscale      9.  1.100 /  9.  1.100</span><br><span class="line">  libswresample   6.  1.100 /  6.  1.100</span><br><span class="line">Input #0, flv, from &#x27;rtmp://172.21.132.230:1935/rtc/test&#x27;:</span><br><span class="line">  Metadata:</span><br><span class="line">    |RtmpSampleAccess: true</span><br><span class="line">    encoder         : Lavf62.3.100</span><br><span class="line">    title           : Streamed by ZLMediaKit(git hash:a972fa8/2025-08-06T12:02:43+08:00,branch:master,build time:2025-08-07T08:12:29)</span><br><span class="line">  Duration: 00:00:00.00, start: 71.000000, bitrate: N/A</span><br><span class="line">  Stream #0:0: Data: none</span><br><span class="line">  Stream #0:1: Audio: aac (LC), 44100 Hz, stereo, fltp, 128 kb/s, start 71.007000</span><br><span class="line">  Stream #0:2: Video: h264 (High), yuv420p(tv, bt470bg/bt470bg/smpte170m, progressive), 1280x720, 2000 kb/s, 30 fps, 30 tbr, 1k tbn, start 71.000000</span><br></pre></td></tr></table></figure>

<p>一眼看出，原始推送的是h264 high profile的，1280x720分辨率，带aac立体声30帧的视频。</p>
<p>先看音频数据，上面的aac, 44100, stereo, fltp分别对应编码器context（相当于编码器的参数配置集）中的codec_id, sample_rate, ch_layout, sample_fmt。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">AVCodecID aid = AV_CODEC_ID_AAC;</span><br><span class="line">AVCodec *acodec = (AVCodec *)avcodec_find_encoder(aid);</span><br><span class="line">LOGD(&quot;found audio encoder for &#x27;%s&#x27;&quot;, avcodec_get_name(aid));</span><br><span class="line">AVCodecContext *acctx = avcodec_alloc_context3(acodec);</span><br><span class="line">acctx-&gt;codec_id = aid;</span><br><span class="line">acctx-&gt;codec_type = AVMEDIA_TYPE_AUDIO;</span><br><span class="line">acctx-&gt;sample_fmt = AV_SAMPLE_FMT_FLTP;</span><br><span class="line">acctx-&gt;ch_layout = AV_CHANNEL_LAYOUT_STEREO;</span><br><span class="line">acctx-&gt;sample_rate = 44100;</span><br></pre></td></tr></table></figure>

<p>再看视频, 上面的h264, yuv420p, 1280x720, 30 fps对应视频编码器的codec_id, pix_fmt, width x height，fps。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">AVCodecID vid = AV_CODEC_ID_H264; </span><br><span class="line">int fps = 30;</span><br><span class="line">vcodec = (AVCodec *)avcodec_find_encoder(vid);</span><br><span class="line">LOGD(&quot;found encoder &#x27;%s&#x27;&quot;, avcodec_get_name(vcodec-&gt;id));</span><br><span class="line">vcctx = avcodec_alloc_context3(vcodec);</span><br><span class="line">vcctx-&gt;codec_id = vcodec-&gt;id;</span><br><span class="line">vcctx-&gt;width = width;</span><br><span class="line">vcctx-&gt;height = height;</span><br><span class="line">vcctx-&gt;time_base = (AVRational)&#123; 1, fps &#125;;</span><br><span class="line">vcctx-&gt;framerate = (AVRational)&#123; fps, 1 &#125;;</span><br><span class="line">vcctx-&gt;pix_fmt = AV_PIX_FMT_YUV420P;</span><br></pre></td></tr></table></figure>
<p>简单核对下上面的信息是否与预期符合，避免一些笔误的问题造成的异常，下面要进行硬核的部分，时间问题。</p>
<ul>
<li>FFMPEG里关于时间的基本概念</li>
</ul>
<p>FFMPEG里面的时间问题，各种网文讲的很玄乎，我们不讲复杂的，拿出一个尺子，上面有刻度有值，对应是真实的毫米，厘米。</p>
<p>而FFMPEG里，音频、视频都是随时间流逝往前递增的，也就可以有一把尺子来度量它，也就是FFMPEG里AVPacket的PTS&#x2F;DTS（index 位置）、Duration（刻度大小）。</p>
<p>但这个刻度不是真实世界里的，并且每种视频格式也都是不一样的。</p>
<p>从摄像头来的原始的YUV420P视频数据（RAW视频），用录制时的帧率来当尺子，FPS为30帧的视频，即1秒分成30格的尺子。</p>
<p>从麦克风来的原始FLTP格式的音频数据（PCM音频），用录制时的采样率业当尺子，sample_rate为 44100Hz的音频，即1秒分成44100格的尺子。</p>
<p>而变成网络视频流后，它还有一个尺子，对于rtmp封装的flv格式，这把尺子是1秒分成1000格，即对应上面的1k tbn。</p>
<p>播放上面的rtmp视频流，如果要实时，并且声音视频“音画同步”，就要求录制时候第1秒的视频和声音，通过编码并打包成flv再通过rtmp协议发送到接收端播放时，也要在第1秒播放出来。<br>这就是ffmpeg中的time_base所谓时间基的概念，更加理论术语的描述可以查专业文献。</p>
<p><strong>说人话就是：</strong></p>
<blockquote>
<p>音视频在不同的尺子上的进度条是要一样的，输入的声音在50%进度条，视频也需要在50%进度条，输出的当然也要在50%进度条。</p>
</blockquote>
<p>上代码帮助理解：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">avcodec_send_frame(vcctx, vFrame);</span><br><span class="line">vindex = 0；</span><br><span class="line">//...</span><br><span class="line">while(avcodec_receive_packet(vcctx, avPacket) == 0)&#123;</span><br><span class="line">  //...</span><br><span class="line">  avPacket-&gt;pts = (vindex++) * (vStream-&gt;time_base.den) / ((vStream-&gt;time_base.num) * fps);</span><br><span class="line">  avPacket-&gt;dts = avPacket-&gt;pts;</span><br><span class="line">  avPacket-&gt;duration = (vStream-&gt;time_base.den) / ((vStream-&gt;time_base.num) * fps);</span><br><span class="line">  //...</span><br><span class="line">&#125;</span><br><span class="line">//...</span><br><span class="line">av_interleaved_write_frame(ofmt_ctx, avPacket);</span><br></pre></td></tr></table></figure>
<p>以编码器送进一个视频AVFrame vFrame（yuv420p），得到一个AVPacket avPacket(h264)为例，如果这是第0个帧（包）vindex&#x3D;0，它是(1&#x2F;30)的尺子（原视频）上的第1个，那么它在（1&#x2F;1000）的尺子（flv视频）上也应该是第0个，pts就是0（dts本文暂时不关注，它与更高级的编码方式有关，这里简单等同于pts）。</p>
<p>那第原视频第2,3,4…帧呢，公式是这样来的：</p>
<p>a是输入的视频帧编号vindex，需要一直++递增；b是输出的视频帧编号，avPacket-&gt;pts。</p>
<p>为了保持进度条一致，需要a * (1&#x2F;30fps) &#x3D; b * (1&#x2F;1000tbn)<br>那么，b &#x3D; a * (1000tbn&#x2F;(1*30fps)) &#x3D; a * 33，也就对应</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">avPacket-&gt;pts = (vindex++) * (vStream-&gt;time_base.den) / ((vStream-&gt;time_base.num) * fps);</span><br></pre></td></tr></table></figure>

<p>上面是为了简化，只讲进度条进度，为了保证声音图像不异常，这一帧视频持续时间（在尺子上占的比例），在不同比例的尺子上也需要一致，这就是duration值。</p>
<p>原始视频的duration就是，30fps的视频，每一帧时长（1&#x2F;30）秒，为了让目标flv视频每一帧也播放同样时长，需要在目标尺子上乘一个系数n才能在不同尺子上占的比例相同，公式是：</p>
<p>(1&#x2F;30fps)秒 &#x3D; n * （1&#x2F;1000tbn）秒 求n值, n &#x3D; 1000tbn&#x2F;30fps &#x3D; 33ms</p>
<p>则：avPacket-&gt;duration &#x3D; (vStream-&gt;time_base.den) &#x2F; ((vStream-&gt;time_base.num) * fps);</p>
<p><strong>！！注意音频的不同</strong></p>
<p>对于音频，把上面的fps概念换成音频录音里的采样率，例如44100，即，原始音频每一帧是（1&#x2F;44100）秒。</p>
<p>但由于音频不是一帧一帧传递的，而是一个打包AVFrame里有nb_samples个音频帧，所以这里就非常容易出现由于概念理解有误，产生的异常声音图象不同步的问题了。</p>
<p>对照视频，我们做同样的pts的计算，上代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">int aindex = 0;</span><br><span class="line">while(avcodec_receive_packet(acctx, aPacket) == 0)&#123;</span><br><span class="line">//...</span><br><span class="line">aPacket-&gt;pts = av_rescale_q_rnd(</span><br><span class="line">    (aindex++) * aFrame-&gt;nb_samples, acctx-&gt;time_base, aStream-&gt;time_base,</span><br><span class="line">    (AVRounding)(AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX));</span><br><span class="line">aPacket-&gt;dts = aPacket-&gt;pts;</span><br><span class="line">aPacket-&gt;duration = av_rescale_q_rnd(aFrame-&gt;nb_samples, acctx-&gt;time_base,</span><br><span class="line">    aStream-&gt;time_base, (AVRounding)(AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX));</span><br><span class="line">av_interleaved_write_frame(ofmt_ctx, aPacket);</span><br><span class="line">//...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>先了解下av_rescale_q_rnd，它的函数定义是：<br>int64_t av_rescale_q_rnd(int64_t a, AVRational bq, AVRational cq, AVRounding rnd)<br>即，把a对应的原始pts（时间基是bq），转到到以时间基cq为标准的新pts值，即上面我们手写公式的ffmpeg预封装实现。</p>
<p>由于上文我们讲了，音频的一个AVFrame、AVPacket里，包含了nb_samples个帧，所以不能简单用上文视频的方式来计算，每编码一个音频Frame，它的时间尺子前进了nb_samples格（以AAC为例，就是1024格,通过它的编码器context的frame_size来获取，取不到以默认值1024计。即：aFrame-&gt;nb_samples &#x3D; acctx-&gt;frame_size? acctx-&gt;frame_size : 1024）。</p>
<p>所以第n个音频包，计算它的输出pts值需要用视频公式基础上，再乘以nb_samples。</p>
<p>a * (1&#x2F;44100hz) &#x3D; b * (1&#x2F;1000tbn)<br>b &#x3D; a * (1000tbn&#x2F;(1*44100hz)) &#x3D; a * 0.02267574<br>newpts &#x3D; 1024 * b &#x3D; a * 23</p>
<p>它的输出duration也一样需要乘以nb_samples。<br>(1&#x2F;44100hz)秒 &#x3D; b * （1&#x2F;1000tbn）秒，<br>b &#x3D; 1000tbn&#x2F;44100hz &#x3D; 0.02267574s<br>newdur &#x3D; 1024 * b &#x3D; 23ms</p>
<ul>
<li>问题定位与解决</li>
</ul>
<p>在源码中打开日志:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">videoTimestamp = cur_pts_v * av_q2d(vStream-&gt;time_base);</span><br><span class="line">audioTimestamp = cur_pts_a * av_q2d(aStream-&gt;time_base);</span><br><span class="line"></span><br><span class="line">LOGD(&quot;Send audio frame index:%d,pts:%lld  dur:%lld %lf %lf&quot;,</span><br><span class="line">  aindex, (long long) aPacket-&gt;pts, aPacket-&gt;duration, videoTimestamp, audioTimestamp);</span><br><span class="line"></span><br><span class="line">LOGD(&quot;Send video frame index:%d,pts:%lld,dts:%lld,duration:%lld&quot;,</span><br><span class="line">  index,</span><br><span class="line">  (long long) avPacket-&gt;pts,</span><br><span class="line">  (long long) avPacket-&gt;dts,</span><br><span class="line">  (long long) avPacket-&gt;duration);</span><br></pre></td></tr></table></figure>

<p>重点是显示发送音频和视频时的index、pts和dur：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">12:06:19.345  D  Send audio frame index:0,pts:0  dur:23 0.033000 0.000000</span><br><span class="line">12:06:19.397  D  Send audio frame index:1,pts:23  dur:23 0.033000 0.000000</span><br><span class="line">12:06:19.435  D  Send audio frame index:2,pts:46  dur:23 0.033000 0.023000</span><br><span class="line">12:06:19.437  D  Send video frame index:2,pts:66,dts:66,duration:33 0.033000 0.046000</span><br><span class="line">12:06:19.439  D  Send video frame index:3,pts:100,dts:100,duration:33 0.033000 0.046000</span><br><span class="line">12:06:19.475  D  Send audio frame index:3,pts:70  dur:23 0.100000 0.046000</span><br><span class="line">12:06:19.516  D  Send audio frame index:4,pts:93  dur:23 0.100000 0.070000</span><br><span class="line">12:06:19.556  D  Send audio frame index:5,pts:116  dur:23 0.100000 0.093000</span><br><span class="line">12:06:19.558  D  Send video frame index:4,pts:133,dts:133,duration:33 0.100000 0.116000</span><br><span class="line">12:06:19.560  D  Send video frame index:5,pts:166,dts:166,duration:33 0.100000 0.116000</span><br><span class="line">12:06:19.595  D  Send audio frame index:6,pts:139  dur:23 0.166000 0.116000</span><br><span class="line">12:06:19.635  D  Send audio frame index:7,pts:163  dur:23 0.166000 0.139000</span><br><span class="line">12:06:19.675  D  Send audio frame index:8,pts:186  dur:23 0.166000 0.163000</span><br><span class="line">12:06:19.677  D  Send video frame index:6,pts:200,dts:200,duration:33 0.166000 0.186000</span><br><span class="line">12:06:19.681  D  Send video frame index:7,pts:233,dts:233,duration:33 0.166000 0.186000</span><br><span class="line">12:06:19.716  D  Send audio frame index:9,pts:209  dur:23 0.233000 0.186000</span><br><span class="line">12:06:19.755  D  Send audio frame index:10,pts:232  dur:23 0.233000 0.209000</span><br><span class="line">12:06:19.795  D  Send audio frame index:11,pts:255  dur:23 0.233000 0.232000</span><br></pre></td></tr></table></figure>

<p>可以看到，audio和video的index都在正常递增（即视频的帧和音频的帧*1024）；<br>每个视频包pts值增加33（四舍五入的），dur是33ms没有问题；<br>每个语音包pts什增加23，dur是22ms也没问题。</p>
<p>videoTimestamp和audioTimestamp是以输出flv视频（1&#x2F;1000）为时间基的，即ms，表示从推流开始的真实时间值，两个值偏差不大则表示音视频是基本同步的。<br>为达成这个效果，一般是编码时原始视频和音频数据都要进fifo（av_fifo和av_audio_fifo），在线程中取出时，比较当前audio和video的输出的pts先后顺序，哪个落后先编码哪个。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">if (av_compare_ts(cur_pts_v, vStream-&gt;time_base,</span><br><span class="line">                          cur_pts_a, aStream-&gt;time_base) &lt;= 0)&#123;</span><br><span class="line">  //encode and send video</span><br><span class="line">&#125;else&#123;</span><br><span class="line">  //encode and send audio</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>看不出太大问题，再从播放端分析，再次掏出ffprobe：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">./ffprobe  -show_frames rtmp://172.21.132.230:1935/rtc/test | grep -E &#x27;(media_type|pts|dur)&#x27;</span><br><span class="line">media_type=video</span><br><span class="line">pts=26000</span><br><span class="line">pts_time=26.000000</span><br><span class="line">duration=N/A</span><br><span class="line">duration_time=N/A</span><br><span class="line">media_type=audio</span><br><span class="line">pts=26006</span><br><span class="line">pts_time=26.006000</span><br><span class="line">duration=23</span><br><span class="line">duration_time=0.023000</span><br><span class="line">media_type=audio</span><br><span class="line">pts=26030</span><br><span class="line">pts_time=26.030000</span><br><span class="line">duration=23</span><br><span class="line">duration_time=0.023000</span><br><span class="line">media_type=video</span><br><span class="line">pts=26033</span><br><span class="line">pts_time=26.033000</span><br><span class="line">duration=N/A</span><br><span class="line">duration_time=N/A</span><br><span class="line">media_type=audio</span><br><span class="line">pts=26053</span><br><span class="line">pts_time=26.053000</span><br><span class="line">duration=23</span><br><span class="line">duration_time=0.023000</span><br><span class="line">media_type=video</span><br><span class="line">pts=26066</span><br><span class="line">pts_time=26.066000</span><br><span class="line">duration=N/A</span><br><span class="line">duration_time=N/A</span><br><span class="line">media_type=audio</span><br><span class="line">pts=26076</span><br><span class="line">pts_time=26.076000</span><br><span class="line">duration=23</span><br><span class="line">duration_time=0.023000</span><br><span class="line">media_type=audio</span><br><span class="line">pts=26099</span><br><span class="line">pts_time=26.099000</span><br><span class="line">duration=23</span><br><span class="line">duration_time=0.023000</span><br><span class="line">media_type=video</span><br><span class="line">pts=26100</span><br><span class="line">pts_time=26.100000</span><br><span class="line">duration=N/A</span><br><span class="line">duration_time=N/A</span><br><span class="line">media_type=audio</span><br><span class="line">pts=26122</span><br><span class="line">pts_time=26.122000</span><br><span class="line">duration=23</span><br><span class="line">duration_time=0.023000</span><br></pre></td></tr></table></figure>

<p>可以看到，audio的pts递增大小是23，dur是33ms，video是33，dur是23ms。<br>那么问题不出在打包发送阶段，还是回到源头。</p>
<ul>
<li>Android录音采集部分</li>
</ul>
<p>看了下源码，录音部分采用的网上随处可见的代码块，采用的44100Hz采样率，立体声，更为通用的16bit打包pcm格式：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">final int mMinBufferSize =</span><br><span class="line">  AudioRecord.getMinBufferSize(44100, AudioFormat.CHANNEL_IN_STEREO, AudioFormat.ENCODING_PCM_16BIT);</span><br><span class="line">AudioRecord audioRecord = new AudioRecord(</span><br><span class="line">  MediaRecorder.AudioSource.DEFAULT,</span><br><span class="line">  DEFAULT_SAMPLE_RATE, DEFAULT_CHANNEL_LAYOUT, DEFAULT_SAMPLE_FORMAT,</span><br><span class="line">  mMinBufferSize);</span><br><span class="line">audioRecord.startRecording();</span><br></pre></td></tr></table></figure>

<p>然后在线程里循环读取，调用JNI接口发送：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">byte[] buffer = new byte[mMinBufferSize];</span><br><span class="line">while(true)&#123;</span><br><span class="line">  int readsize = audioRecord.read(buffer, 0, mMinBufferSize);</span><br><span class="line">  if(readsize &gt; 0 &amp;&amp; isRecording)&#123;</span><br><span class="line">    sendAudio(buffer);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>JNI中处理也很简单，读取后进audio fifo：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Java_cn_mbstudio_mewhip_MainActivity_sendAudio(JNIEnv *env, </span><br><span class="line">  jclass clazz, jbyteArray data) &#123;</span><br><span class="line"></span><br><span class="line">  int len = env-&gt;GetArrayLength (data);</span><br><span class="line">  int inputAudioSamples = len / 4;  //PCM，立体声，非打包，每一个Frame中包含的单声道采样次数</span><br><span class="line">  unsigned char* buf = new unsigned char[len];</span><br><span class="line">  env-&gt;GetByteArrayRegion(data, 0, len, reinterpret_cast&lt;jbyte*&gt;(buf));</span><br><span class="line"></span><br><span class="line">  AVAudioFifo *aFifo = av_audio_fifo_alloc(AV_SAMPLE_FMT_S16, 2, inputAudioSamples);</span><br><span class="line">  av_audio_fifo_write(aFifo, (void **)&amp;buf, inputAudioSamples);</span><br><span class="line"></span><br><span class="line">  //...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>再看FFMPEG将上述原始PCM编码成AAC发送的部分（不再重复上面的PTS设置部分）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">//分配待编码的AVFrame，格式就是AAC编码器context(acctx)要求的PCM参数值</span><br><span class="line">AVCodecID aid = AV_CODEC_ID_AAC;</span><br><span class="line">acodec = (AVCodec *)avcodec_find_encoder(aid);</span><br><span class="line">acctx = avcodec_alloc_context3(acodec);</span><br><span class="line">acctx-&gt;codec_id = aid;</span><br><span class="line">acctx-&gt;codec_type = AVMEDIA_TYPE_AUDIO;</span><br><span class="line">acctx-&gt;sample_fmt = acodec-&gt;sample_fmts?acodec-&gt;sample_fmts[0]:AV_SAMPLE_FMT_FLTP;</span><br><span class="line">acctx-&gt;ch_layout = AV_CHANNEL_LAYOUT_STEREO;</span><br><span class="line">acctx-&gt;sample_rate = 44100;</span><br><span class="line">//...</span><br><span class="line"></span><br><span class="line">aFrame = av_frame_alloc();</span><br><span class="line">aFrame-&gt;format = acctx-&gt;sample_fmt;</span><br><span class="line">aFrame-&gt;ch_layout = acctx-&gt;ch_layout;</span><br><span class="line">aFrame-&gt;sample_rate = acctx-&gt;sample_rate;</span><br><span class="line">aFrame-&gt;nb_samples = acctx-&gt;frame_size ? acctx-&gt;frame_size: inputAudioSamples;</span><br><span class="line">av_frame_get_buffer(aFrame, 0);</span><br><span class="line"></span><br><span class="line">SwrContext *m_swrCtx = swr_alloc();</span><br><span class="line">AVChannelLayout stero = AV_CHANNEL_LAYOUT_STEREO;</span><br><span class="line">swr_alloc_set_opts2(&amp;m_swrCtx, </span><br><span class="line">  //aac settings</span><br><span class="line">  (const AVChannelLayout *)&amp;aFrame-&gt;ch_layout, (AVSampleFormat)aFrame-&gt;format, aFrame-&gt;sample_rate,</span><br><span class="line">  //android pcm settings</span><br><span class="line">  &amp;stero, AV_SAMPLE_FMT_S16, 44100, </span><br><span class="line">  0, NULL);</span><br><span class="line">ret = swr_init(m_swrCtx);</span><br><span class="line">if (ret &lt; 0) &#123;</span><br><span class="line">    LOGE(&quot;error init swr：%s&quot;, av_err2str(ret));</span><br><span class="line">    return nullptr;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//...</span><br><span class="line"></span><br><span class="line">if(av_audio_fifo_size(aFifo) &gt;= inputAudioSamples)&#123;</span><br><span class="line">  pthread_mutex_lock(&amp;afLock);</span><br><span class="line">  av_audio_fifo_read(aFifo, (void **)&amp;(buf), inputAudioSamples);</span><br><span class="line">  pthread_mutex_unlock(&amp;afLock);</span><br><span class="line"></span><br><span class="line">  ret = av_frame_make_writable(aFrame);</span><br><span class="line">  if(ret &lt; 0)&#123;</span><br><span class="line">      LOGE(&quot;av frame error:%s&quot;, av_err2str(ret));</span><br><span class="line">      break;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  //make sure: dst_nb_samples / dest_sample = src_nb_sample / src_sample_rate</span><br><span class="line">  int dst_nb_samples = av_rescale_rnd(</span><br><span class="line">    swr_get_delay(m_swrCtx, aFrame-&gt;sample_rate) +  aFrame-&gt;nb_samples,</span><br><span class="line">    acctx-&gt;sample_rate/*dst*/, aFrame-&gt;sample_rate/*src*/, AV_ROUND_UP);</span><br><span class="line">    </span><br><span class="line">  //av_assert0(dst_nb_samples == aFrame-&gt;nb_samples);</span><br><span class="line"></span><br><span class="line">  swr_convert(m_swrCtx, aFrame-&gt;data, aFrame-&gt;nb_samples, </span><br><span class="line">    (const uint8_t **) &amp;(buf), inputAudioSamples);</span><br><span class="line"></span><br><span class="line">  //avcodec_send_frame ...</span><br><span class="line">  //avcodec_receive_packet ...</span><br><span class="line">  //set pts, dts, duration ...</span><br><span class="line">  //av_interleaved_write_frame ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>由于新版本FFMPEG不再支持Android录音采集到的16BIT打包PCM，要求的是AV_SAMPLE_FMT_FLTP, 是16BIT分片PCM，所以要swr重采样转换一下。</p>
<p>这和Android摄像头采集的是NV21或ImageFormat.YUV_420_888，而不是FFMPEG视频编码器要求的输入数据是YUV420P（AV_PIX_FMT_YUV420P），需要libyuv转换或sws_scale转换是一个逻辑。</p>
<p>看到一行可疑代码：<br><code>//av_assert0(dst_nb_samples == aFrame-&gt;nb_samples);</code></p>
<p>问了原因就是这里会崩溃……所以注释掉了……</p>
<p>按道理，AAC编码器要求的nb_samples是1024，Android那边也应该是每次送1024<em>2</em>2 （16bit需x2, 立体声需x2,打包方式，PCM就是LRLRLRLR的数据，buffer长度简单除4就是每次读取的nb_samples）。<br>打印一下Android送进JNI的数据长度，发现是7104，除以4就是1776……</p>
<p>问就是Android开发文档要求的：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bufferSizeInBytes – the total size (in bytes) of the buffer where audio data is written to during the recording. New audio data can be read from this buffer in smaller chunks than this size. See getMinBufferSize(int, int, int) to determine the minimum required buffer size for the successful creation of an AudioRecord instance. Using values smaller than getMinBufferSize() will result in an initialization failure.</span><br></pre></td></tr></table></figure>

<p>所以Android那边音频采集的缓冲区是7104，每次也读取了7104，然后到了JNI这边强行截取了1776的前面的1024数据进行编码……</p>
<p>上述程序员因为不明白FFMPEG的音频编码的参数真实含义，以及SWR的真实作用，就胡乱调试到不奔溃就行（道理是这么个道理），结果就是代码以奇怪的方式跑起来了……起来了……来了……了……</p>
<p>知道了原因，只需要修改Android每次发送到JNI的数据长度（即PCM帧数），让AVFrame保证每帧里面有AAC要求的1024个nb_samples，就能正常跑起来了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">int buffsize = 1024*4;    //AV_SAMPLE_FMT_S16 4096/2(stero)/2(16bit)=1024</span><br><span class="line">byte[] buffer = new byte[buffsize];</span><br><span class="line">while(true)&#123;</span><br><span class="line">    int readsize = audioRecord.read(buffer, 0, buffsize);</span><br><span class="line">    if(readsize &gt; 0 &amp;&amp; isRecording)&#123;</span><br><span class="line">        sendAudio(buffer);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2025-09-18</span><i class="fa fa-tag"></i><a class="tag" href="/tags/技术分析/" title="技术分析">技术分析 </a><a class="tag" href="/tags/程序开发/" title="程序开发">程序开发 </a><a class="tag" href="/tags/流媒体技术/" title="流媒体技术">流媒体技术 </a></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank"></a></div><div class="weibo"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></div><div class="twitter"><a class="fa fa-twitter" target="_blank" rel="noopener" href="http://twitter.com/home?status=,https://mbstudio.cn/ffmpeg_debug/,MBSTUDIO,FFMPEG代码（API）推流RTMP的音视频不同步问题分析,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/ffmpeg_mediacodec/" title="FFMPEG硬件编码（MediaCodec）异常降低码率BUG">上一篇</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/wertc_no_id/" title="WebRTC 设备枚举ID为空异常">下一篇</a></li></ul></div><a id="comments"></a><div id="vcomments" style="margin:0 30px;"></div><script src="/js/av-min.js"></script><script src="/js/Valine.min.js"></script><script>var valine = new Valine({
  el:'#vcomments',
  notify:false || false, 
  verify:true|| false, 
  app_id:'NJ38qTX1M6HwqDECSFibkJnD-gzGzoHsz',
  app_key:'xsgCybaxfNqU9qWtVSa1CsPU',
  placeholder:'谢绝广告。',
  path: window.location.pathname,
  avatar:''
})

</script></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/baidu.js"> </script></body></html>